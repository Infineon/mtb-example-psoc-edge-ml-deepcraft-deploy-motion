[Click here](../README.md) to view the README.

## Design and implementation

The design of this application is minimalistic to get started with code examples on PSOC&trade; Edge MCU devices. All PSOC&trade; Edge E84 MCU applications have a dual-CPU three-project structure to develop code for the CM33 and CM55 cores. The CM33 core has two separate projects for the secure processing environment (SPE) and non-secure processing environment (NSPE). A project folder consists of various subfolders, each denoting a specific aspect of the project. The three project folders are as follows:

**Table 1. Application projects**

Project | Description
--------|------------------------
*proj_cm33_s* | Project for CM33 secure processing environment (SPE)
*proj_cm33_ns* | Project for CM33 non-secure processing environment (NSPE)
*proj_cm55* | CM55 project

<br>

### Movement Type detection

This example includes the movement type detection model that works out-of-box without requiring any changes.

The model takes data from a motion sensor (BMI270) to detect various movement type based on the "Movement Type Detection" starter project in DEEPCRAFT&trade; Studio. These activities are shaking and circling.

DEEPCRAFT&trade; Studio generates the *model.c/h* file that contains the code required for processing the data before being fed to the ML model and the code needed for model inferencing.

The input data consists of the 3-axis accelerometer and 3-axis gyroscope raw data from the BMI270 IMU. The data from the IMU is configured at 50 Hz data rate and the PSOC&trade; Edge MCU receives the data from IMU once every 200 ms. This is achieved using the internal hardware FIFO within the BMI270 IMU â€“ only when adequate number of samples are received (based on the FIFO watermark level), a hardware interrupt triggers the PSOC&trade; Edge MCU to receive the FIFO data and perform data processing.

All IMU-related configurations are set in the config.h file in the CM33 NS and CM55 projects. The data received from FIFO is fed into the data processing code generated by DEEPCRAFT&trade; Studio using the `IMAI_enqueue` API after 10 data frames are received from the IMU. After the processing is done, the `IMAI_dequeue` API returns the results as scores corresponding to each label. All label scores along with the label corresponding to the maximum score is printed on the UART terminal.

The pre-processor uses a 50-frame sliding window for evaluating the data over a period of 2 seconds as the data rate is 50 Hz. The preprocessing layers for the movement type detection application is shown in **Figure 1**.

**Figure 1. Movement type detection pre-processing layers**

![](../images/deploy-motion-preprocessing.png)

The movement type detection model is a 2D convolutional neural network that contains several convolutional layers, batch normalization, activation functions, pooling, and a dense layer for classification into three classes, as shown in **Figure 2**.

**Figure 2. Movement type detection model layers**

![](../images/deploy-motion-model-layers.png)


### Memory placement of model and arena data

On CM33 + NNLite, it is recommended to place the model weights and arena data in the SRAM for best performance. Place the model weights by defining the `CY_ML_MODEL_MEM` macro to the desired memory section from the CM33 NS linker script. For the arena data, use the `CY_ML_ARENA_MEM` macro.

In this code example, the `CY_ML_MODEL_MEM` macro is set to the `.cy_sram_code` section using the CM33 project *Makefile*, ensuring the model data is placed in SRAM for optimal performance. The `CY_ML_ARENA_MEM` macro is not defined in this example so the arena buffer gets placed in the default data segment.

> **Note:** The memory section to which the macros are assigned must be defined in the CM33 NS linker script.

On CM55 + U55, it is recommended to place the model weights in the system SRAM (SoCMEM) for best performance while the arena data must be placed in the system SRAM (SoCMEM) for the proper functioning of the application. Configure the model data placement using the `CY_ML_MODEL_MEM` macro and the arena data using the `CY_ML_ARENA_MEM` macro.

In this code example, both `CY_ML_MODEL_MEM` and `CY_ML_ARENA_MEM` macros are set to the `.cy_socmem_data` section using the CM55 project Makefile, ensuring the model and arena data are placed in the System SRAM (SoCMEM) for optimal performance.

> **Note:** The memory section to which the macros are assigned must be defined in the CM55 linker script.


### Generating the model

This code example ships with the movement type detection files (*model.c/h*) produced by DEEPCRAFT&trade; Studio. Use DEEPCRAFT&trade; Studio to capture the new data and review, modify, or generate new models for evaluation. For more information, see [Deploy model on PSOC&trade; 6 and PSOC&trade; Edge boards](https://developer.imagimob.com/deepcraft-studio/deployment/deploy-models-supported-boards/deploy-model-PSOC-6-PSOC-Edge). For details on generating, optimizing, and validating the model code using DEEPCRAFT&trade; Studio, see [Code generation for Infineon boards](https://developer.imagimob.com/deepcraft-studio/code-generation/code-gen-infineon-boards).


### Running the generated model

1. Generate the model files as described in [Generating the model](#generating-the-model).

2. Open the *common.mk* file and set `ML_DEEPCRAFT_CPU` to 'cm55' or 'cm33'.

3. Open the *common.mk* file and set `IMU_ENABLE_SENSOR` to `ACCELEROMETER`, `GYROSCOPE`, or `ACCELEROMETER_GYROSCOPE` to enable 3-axis accelerometer only, 3-axis gyroscope only, or both 3-axis accelerometer and 3-axis gyroscope, respectively based on the model used in your application. By default, `IMU_ENABLE_SENSOR` is set to `ACCELEROMETER_GYROSCOPE`.

4. Open the *proj_cmxx/Makefile* file and set `NN_TYPE` to 'int8x8' or 'float' to select the desired quantization

5. Program the device as described in the [Operation](../README.md#operation) Section

<br>